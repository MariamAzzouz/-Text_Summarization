{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10149709,"sourceType":"datasetVersion","datasetId":6265728}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T14:47:26.421110Z","iopub.execute_input":"2024-12-27T14:47:26.421535Z","iopub.status.idle":"2024-12-27T14:47:26.837588Z","shell.execute_reply.started":"2024-12-27T14:47:26.421483Z","shell.execute_reply":"2024-12-27T14:47:26.836609Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/pdf-test/AMovieRecommenderSystemMOVREC.pdf\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"   !pip install numpy transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T14:47:26.839856Z","iopub.execute_input":"2024-12-27T14:47:26.840295Z","iopub.status.idle":"2024-12-27T14:47:36.149724Z","shell.execute_reply.started":"2024-12-27T14:47:26.840258Z","shell.execute_reply":"2024-12-27T14:47:36.148857Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"   from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n   model_name = \"facebook/bart-large-cnn\"  # Example model for summarization\n   tokenizer = AutoTokenizer.from_pretrained(model_name)\n   model = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T14:47:36.151051Z","iopub.execute_input":"2024-12-27T14:47:36.151347Z","iopub.status.idle":"2024-12-27T14:48:03.618895Z","shell.execute_reply.started":"2024-12-27T14:47:36.151318Z","shell.execute_reply":"2024-12-27T14:48:03.618031Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d10ec9d7c88049d0b2895a3dbf4b7d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b70b1037a04419484b49ba0fa703241"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20ed005fd12446baa639e6217632de8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e2ca8882f514143af6b1fa7e6cc281a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a330956fae4b4e9390520520a3fdf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a5267c9eab4017a95510d6fa2080d2"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"   from datasets import load_dataset\n\n   dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split='train')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T14:48:03.620950Z","iopub.execute_input":"2024-12-27T14:48:03.621421Z","iopub.status.idle":"2024-12-27T14:48:17.626626Z","shell.execute_reply.started":"2024-12-27T14:48:03.621388Z","shell.execute_reply":"2024-12-27T14:48:17.625618Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0514512acb624af4b1ca63f5ccd50627"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aebb5c8e6934aa0b97a657c602bdf35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06ae9e9603a340b48450d656702bf2e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"692357990f534cd9b927757040b8e9ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c0b9c1166c8409db15f8853c33e7265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519d7231be9f42f9ade660ca6a7309a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eabe93eb1d4448a39ba8e2a01d00b5a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad904f72e8654c6489f66e4a489262ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebf730b148be4f9a81b1e7a2489f2038"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"   def preprocess_function(examples):\n       inputs = [doc for doc in examples['article']]\n       model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n\n       # Setup the tokenizer for targets\n       with tokenizer.as_target_tokenizer():\n           labels = tokenizer(examples['highlights'], max_length=128, truncation=True)\n\n       model_inputs[\"labels\"] = labels[\"input_ids\"]\n       return model_inputs\n\n   tokenized_datasets = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T14:48:17.627708Z","iopub.execute_input":"2024-12-27T14:48:17.628256Z","iopub.status.idle":"2024-12-27T14:54:49.255272Z","shell.execute_reply.started":"2024-12-27T14:48:17.628229Z","shell.execute_reply":"2024-12-27T14:54:49.254272Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3103da267b1943888af30a1f8ffdccec"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"   from transformers import TrainingArguments, Trainer\n\n   training_args = TrainingArguments(\n       output_dir=\"./results\",\n       evaluation_strategy=\"epoch\",\n       learning_rate=2e-4,\n       per_device_train_batch_size=8,\n       per_device_eval_batch_size=8,\n       num_train_epochs=1,\n       weight_decay=0.01,\n       save_total_limit=3,\n   )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:22:55.959063Z","iopub.execute_input":"2024-12-27T15:22:55.959758Z","iopub.status.idle":"2024-12-27T15:22:55.989521Z","shell.execute_reply.started":"2024-12-27T15:22:55.959724Z","shell.execute_reply":"2024-12-27T15:22:55.988615Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"   from transformers import DataCollatorForSeq2Seq\n\n   data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n   trainer = Trainer(\n       model=model,\n       args=training_args,\n       train_dataset=tokenized_datasets,\n       eval_dataset=tokenized_datasets,\n       tokenizer=tokenizer,\n       data_collator=data_collator,\n   )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:22:58.274335Z","iopub.execute_input":"2024-12-27T15:22:58.275049Z","iopub.status.idle":"2024-12-27T15:22:58.290353Z","shell.execute_reply.started":"2024-12-27T15:22:58.275017Z","shell.execute_reply":"2024-12-27T15:22:58.289514Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/710649148.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"   trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:23:00.826072Z","iopub.execute_input":"2024-12-27T15:23:00.826779Z","iopub.status.idle":"2024-12-27T21:25:43.494056Z","shell.execute_reply.started":"2024-12-27T15:23:00.826745Z","shell.execute_reply":"2024-12-27T21:25:43.490887Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10172' max='35890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10172/35890 6:02:37 < 15:16:59, 0.47 it/s, Epoch 0.28/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2486\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/trained_model\")\ntokenizer.save_pretrained(\"/kaggle/working/trained_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:25:47.553103Z","iopub.execute_input":"2024-12-27T21:25:47.553457Z","iopub.status.idle":"2024-12-27T21:25:51.144952Z","shell.execute_reply.started":"2024-12-27T21:25:47.553425Z","shell.execute_reply":"2024-12-27T21:25:51.144138Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/trained_model/tokenizer_config.json',\n '/kaggle/working/trained_model/special_tokens_map.json',\n '/kaggle/working/trained_model/vocab.json',\n '/kaggle/working/trained_model/merges.txt',\n '/kaggle/working/trained_model/added_tokens.json',\n '/kaggle/working/trained_model/tokenizer.json')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import torch\n\ndef summarize(text):\n    # Check if a GPU is available and set the device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Move the model to the appropriate device\n    model.to(device)\n    \n    # Tokenize the input text\n    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    \n    # Move input tensors to the same device as the model\n    input_ids = inputs[\"input_ids\"].to(device)\n    \n    # Generate the summary\n    summary_ids = model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n    \n    # Decode and return the summary\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:25:54.955842Z","iopub.execute_input":"2024-12-27T21:25:54.956476Z","iopub.status.idle":"2024-12-27T21:25:54.962743Z","shell.execute_reply.started":"2024-12-27T21:25:54.956444Z","shell.execute_reply":"2024-12-27T21:25:54.961814Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"   test_text = \"Recently, the topic of Artificial Intelligence Generated Content (AIGC) has witnessed unprecedented advancements 1NExT++ Research Center, National University of Singapore, Singapore. Correspondence to: Hao Fei <haofei37@nus.edu.sg>. Proceedings of the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author(s). with certain technologies, such as ChatGPT for text generation (OpenAI, 2022a) and diffusion models for visual generation (Fan et al., 2022). Among these, the rise of Large Language Models (LLMs) has been particularly remarkable, e.g., Flan-T5 (Chung et al., 2022), Vicuna (Chiang et al., 2023), LLaMA (Touvron et al., 2023) and Alpaca (Taori et al., 2023), showcasing their formidable human-level language reasoning and decision-making capabilities, shining a light on the path of Artificial General Intelligence (AGI). Our world is inherently multimodal, and humans perceive the world with different sensory organs for varied modal information, such as language, images, videos, and sounds, which often complement and synergize with each other. With such intuition, the purely text-based LLMs have recently been endowed with other modal understanding and perception capabilities of image, video, audio, etc. A notable approach involves employing adapters that align pre-trained encoders in other modalities to textual LLMs.This endeavor has led to the rapid development of multimodal LLMs (MM-LLMs), such as BLIP-2 (Li et al., 2023c), Flamingo (Alayrac et al., 2022), MiniGPT-4 (Zhu et al., 2023), Video-LLaMA (Zhang et al., 2023c), LLaVA (Liu et al., 2023b), PandaGPT (Su et al., 2023), and SpeechGPT (Zhang et al., 2023b). Nevertheless, most of these efforts pay attention to the multimodal content understanding at the input side. Lately, fewer works have considered multimodal generation, such as Emu (Sun et al., 2023), DREAMLLM (Dong et al., 2023), GILL (Koh et al., 2023), SEED (Ge et al., 2023). Notably, these models are confined to generating interleaved texts and images. We emphasize that natural human cognition and communication indispensably require seamless transitions between any modalities of information. This makes the exploration of any-to-any MM-LLMs critical, i.e., the ability to accept inputs in any modality and deliver responses in any appropriate modality.\"\n   print(summarize(test_text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:26:01.186157Z","iopub.execute_input":"2024-12-27T21:26:01.187243Z","iopub.status.idle":"2024-12-27T21:26:02.633983Z","shell.execute_reply.started":"2024-12-27T21:26:01.187192Z","shell.execute_reply":"2024-12-27T21:26:02.632910Z"}},"outputs":[{"name":"stdout","text":"NEW: \"It's a very bad day for us,\" the victim's family says .\nNEW: The victim was shot in the head, police say .\nPolice say the suspect, who is in critical condition in hospital, was shot .\nThe suspect is identified as a 17-year-old boy, who was fatally shot .\n","output_type":"stream"}],"execution_count":17},{"cell_type":"raw","source":"!pip install PyPDF2 transformers torch","metadata":{}},{"cell_type":"code","source":"!pip install PyPDF2 transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:26:22.396994Z","iopub.execute_input":"2024-12-27T21:26:22.397703Z","iopub.status.idle":"2024-12-27T21:26:32.486829Z","shell.execute_reply.started":"2024-12-27T21:26:22.397668Z","shell.execute_reply":"2024-12-27T21:26:32.485993Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"!pip install PyPDF2 transformers torch","metadata":{"execution":{"iopub.status.busy":"2024-12-09T15:01:06.614785Z","iopub.execute_input":"2024-12-09T15:01:06.615041Z"}}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\n\n# Load the fine-tuned model and tokenizer\nmodel_path = \"/kaggle/working/trained_model\"  # Path where your model is saved\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n\n# Move the model to the appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:26:36.753994Z","iopub.execute_input":"2024-12-27T21:26:36.754378Z","iopub.status.idle":"2024-12-27T21:26:38.523993Z","shell.execute_reply.started":"2024-12-27T21:26:36.754343Z","shell.execute_reply":"2024-12-27T21:26:38.523104Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import PyPDF2\n\ndef extract_text_from_pdf(file_path):\n    with open(file_path, 'rb') as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text.split('\\n\\n')  # Split text into paragraphs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:26:46.789629Z","iopub.execute_input":"2024-12-27T21:26:46.790474Z","iopub.status.idle":"2024-12-27T21:26:46.925685Z","shell.execute_reply.started":"2024-12-27T21:26:46.790442Z","shell.execute_reply":"2024-12-27T21:26:46.925004Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def summarize_paragraphs(paragraphs):\n    summaries = []\n    for paragraph in paragraphs:\n        if paragraph.strip():  # Check if the paragraph is not empty\n            inputs = tokenizer(paragraph, return_tensors=\"pt\", max_length=1024, truncation=True)\n            input_ids = inputs[\"input_ids\"].to(device)\n            summary_ids = model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n            summaries.append(summary)\n    return summaries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:27:03.152323Z","iopub.execute_input":"2024-12-27T21:27:03.153139Z","iopub.status.idle":"2024-12-27T21:27:03.161277Z","shell.execute_reply.started":"2024-12-27T21:27:03.153108Z","shell.execute_reply":"2024-12-27T21:27:03.160345Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def summarize_pdf(file_path):\n    paragraphs = extract_text_from_pdf(file_path)\n    summaries = summarize_paragraphs(paragraphs)\n    for i, summary in enumerate(summaries):\n        print(f\"Paragraph {i+1} Summary: {summary}\\n\")\n\n# Example usage\npdf_file_path = \"/kaggle/input/pdf-test/AMovieRecommenderSystemMOVREC.pdf\"  # Replace with your PDF file path\nsummarize_pdf(pdf_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:27:07.837110Z","iopub.execute_input":"2024-12-27T21:27:07.837942Z","iopub.status.idle":"2024-12-27T21:27:09.966882Z","shell.execute_reply.started":"2024-12-27T21:27:07.837910Z","shell.execute_reply":"2024-12-27T21:27:09.965984Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1493: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Paragraph 1 Summary: \n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import PyPDF2\n\ndef extract_text_from_pdf(file_path):\n    with open(file_path, 'rb') as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text.split('\\n\\n')  # Split text into paragraphs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:27:20.528245Z","iopub.execute_input":"2024-12-27T21:27:20.528951Z","iopub.status.idle":"2024-12-27T21:27:20.534400Z","shell.execute_reply.started":"2024-12-27T21:27:20.528916Z","shell.execute_reply":"2024-12-27T21:27:20.533522Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load the tokenizer and model\nmodel_name = \"facebook/bart-large-cnn\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\ndef summarize_paragraphs(paragraphs):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    summaries = []\n    for paragraph in paragraphs:\n        if paragraph.strip():  # Check if the paragraph is not empty\n            inputs = tokenizer(\"summarize: \" + paragraph, return_tensors=\"pt\", max_length=1024, truncation=True)\n            input_ids = inputs[\"input_ids\"].to(device)\n            summary_ids = model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n            summaries.append(summary)\n    return summaries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:27:33.182746Z","iopub.execute_input":"2024-12-27T21:27:33.183468Z","iopub.status.idle":"2024-12-27T21:27:44.767512Z","shell.execute_reply.started":"2024-12-27T21:27:33.183437Z","shell.execute_reply":"2024-12-27T21:27:44.766692Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def summarize_pdf(file_path):\n    paragraphs = extract_text_from_pdf(file_path)\n    summaries = summarize_paragraphs(paragraphs)\n    for i, summary in enumerate(summaries):\n        print(f\"Paragraph {i+1} Summary: {summary}\\n\")\n\n# Example usage\npdf_file_path = \"/kaggle/input/pdf-test/AMovieRecommenderSystemMOVREC.pdf\"\nsummarize_pdf(pdf_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:27:49.735223Z","iopub.execute_input":"2024-12-27T21:27:49.736340Z","iopub.status.idle":"2024-12-27T21:27:51.547366Z","shell.execute_reply.started":"2024-12-27T21:27:49.736289Z","shell.execute_reply":"2024-12-27T21:27:51.546680Z"}},"outputs":[{"name":"stdout","text":"Paragraph 1 Summary: A Movie Recommender System: MOVREC is published in the International Journal of Comput er Applic ations. It is based on collaborative filtering that makes use of the information provided by users. It then recommends the movies that is best suited to the user at that time. The recommended movie list is sorted according to the ratings given to these movies by previous users.\n\n","output_type":"stream"}],"execution_count":26}]}