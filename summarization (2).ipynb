{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-12-27T14:47:26.421535Z","iopub.status.busy":"2024-12-27T14:47:26.421110Z","iopub.status.idle":"2024-12-27T14:47:26.837588Z","shell.execute_reply":"2024-12-27T14:47:26.836609Z","shell.execute_reply.started":"2024-12-27T14:47:26.421483Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/pdf-test/AMovieRecommenderSystemMOVREC.pdf\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T14:47:26.840295Z","iopub.status.busy":"2024-12-27T14:47:26.839856Z","iopub.status.idle":"2024-12-27T14:47:36.149724Z","shell.execute_reply":"2024-12-27T14:47:36.148857Z","shell.execute_reply.started":"2024-12-27T14:47:26.840258Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]}],"source":["   !pip install numpy transformers datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T14:47:36.151347Z","iopub.status.busy":"2024-12-27T14:47:36.151051Z","iopub.status.idle":"2024-12-27T14:48:03.618895Z","shell.execute_reply":"2024-12-27T14:48:03.618031Z","shell.execute_reply.started":"2024-12-27T14:47:36.151318Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d10ec9d7c88049d0b2895a3dbf4b7d66","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b70b1037a04419484b49ba0fa703241","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20ed005fd12446baa639e6217632de8e","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e2ca8882f514143af6b1fa7e6cc281a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38a330956fae4b4e9390520520a3fdf3","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3a5267c9eab4017a95510d6fa2080d2","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["   from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","   model_name = \"facebook/bart-large-cnn\"  \n","   tokenizer = AutoTokenizer.from_pretrained(model_name)\n","   model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T14:48:03.621421Z","iopub.status.busy":"2024-12-27T14:48:03.620950Z","iopub.status.idle":"2024-12-27T14:48:17.626626Z","shell.execute_reply":"2024-12-27T14:48:17.625618Z","shell.execute_reply.started":"2024-12-27T14:48:03.621388Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0514512acb624af4b1ca63f5ccd50627","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4aebb5c8e6934aa0b97a657c602bdf35","version_major":2,"version_minor":0},"text/plain":["train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06ae9e9603a340b48450d656702bf2e8","version_major":2,"version_minor":0},"text/plain":["train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"692357990f534cd9b927757040b8e9ea","version_major":2,"version_minor":0},"text/plain":["train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c0b9c1166c8409db15f8853c33e7265","version_major":2,"version_minor":0},"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"519d7231be9f42f9ade660ca6a7309a1","version_major":2,"version_minor":0},"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eabe93eb1d4448a39ba8e2a01d00b5a0","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad904f72e8654c6489f66e4a489262ce","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebf730b148be4f9a81b1e7a2489f2038","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["   from datasets import load_dataset\n","\n","   dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split='train')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T14:48:17.628256Z","iopub.status.busy":"2024-12-27T14:48:17.627708Z","iopub.status.idle":"2024-12-27T14:54:49.255272Z","shell.execute_reply":"2024-12-27T14:54:49.254272Z","shell.execute_reply.started":"2024-12-27T14:48:17.628229Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3103da267b1943888af30a1f8ffdccec","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/287113 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}],"source":["   def preprocess_function(examples):\n","       inputs = [doc for doc in examples['article']]\n","       model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n","\n","       \n","       with tokenizer.as_target_tokenizer():\n","           labels = tokenizer(examples['highlights'], max_length=128, truncation=True)\n","\n","       model_inputs[\"labels\"] = labels[\"input_ids\"]\n","       return model_inputs\n","\n","   tokenized_datasets = dataset.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T15:22:55.959758Z","iopub.status.busy":"2024-12-27T15:22:55.959063Z","iopub.status.idle":"2024-12-27T15:22:55.989521Z","shell.execute_reply":"2024-12-27T15:22:55.988615Z","shell.execute_reply.started":"2024-12-27T15:22:55.959724Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["   from transformers import TrainingArguments, Trainer\n","\n","   training_args = TrainingArguments(\n","       output_dir=\"./results\",\n","       evaluation_strategy=\"epoch\",\n","       learning_rate=2e-4,\n","       per_device_train_batch_size=8,\n","       per_device_eval_batch_size=8,\n","       num_train_epochs=1,\n","       weight_decay=0.01,\n","       save_total_limit=3,\n","   )"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T15:22:58.275049Z","iopub.status.busy":"2024-12-27T15:22:58.274335Z","iopub.status.idle":"2024-12-27T15:22:58.290353Z","shell.execute_reply":"2024-12-27T15:22:58.289514Z","shell.execute_reply.started":"2024-12-27T15:22:58.275017Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_23/710649148.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]}],"source":["   from transformers import DataCollatorForSeq2Seq\n","\n","   data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","   trainer = Trainer(\n","       model=model,\n","       args=training_args,\n","       train_dataset=tokenized_datasets,\n","       eval_dataset=tokenized_datasets,\n","       tokenizer=tokenizer,\n","       data_collator=data_collator,\n","   )"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T15:23:00.826779Z","iopub.status.busy":"2024-12-27T15:23:00.826072Z","iopub.status.idle":"2024-12-27T21:25:43.494056Z","shell.execute_reply":"2024-12-27T21:25:43.490887Z","shell.execute_reply.started":"2024-12-27T15:23:00.826745Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10172' max='35890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10172/35890 6:02:37 < 15:16:59, 0.47 it/s, Epoch 0.28/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2486\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["   trainer.train()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:25:47.553457Z","iopub.status.busy":"2024-12-27T21:25:47.553103Z","iopub.status.idle":"2024-12-27T21:25:51.144952Z","shell.execute_reply":"2024-12-27T21:25:51.144138Z","shell.execute_reply.started":"2024-12-27T21:25:47.553425Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('/kaggle/working/trained_model/tokenizer_config.json',\n"," '/kaggle/working/trained_model/special_tokens_map.json',\n"," '/kaggle/working/trained_model/vocab.json',\n"," '/kaggle/working/trained_model/merges.txt',\n"," '/kaggle/working/trained_model/added_tokens.json',\n"," '/kaggle/working/trained_model/tokenizer.json')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"/kaggle/working/trained_model\")\n","tokenizer.save_pretrained(\"/kaggle/working/trained_model\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:25:54.956476Z","iopub.status.busy":"2024-12-27T21:25:54.955842Z","iopub.status.idle":"2024-12-27T21:25:54.962743Z","shell.execute_reply":"2024-12-27T21:25:54.961814Z","shell.execute_reply.started":"2024-12-27T21:25:54.956444Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","def summarize(text):\n","    \n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    \n","    \n","    model.to(device)\n","    \n","    # Tokenize the input text\n","    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n","    \n","    \n","    input_ids = inputs[\"input_ids\"].to(device)\n","    \n"," \n","    summary_ids = model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","    \n","    \n","    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:26:01.187243Z","iopub.status.busy":"2024-12-27T21:26:01.186157Z","iopub.status.idle":"2024-12-27T21:26:02.633983Z","shell.execute_reply":"2024-12-27T21:26:02.632910Z","shell.execute_reply.started":"2024-12-27T21:26:01.187192Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["NEW: \"It's a very bad day for us,\" the victim's family says .\n","NEW: The victim was shot in the head, police say .\n","Police say the suspect, who is in critical condition in hospital, was shot .\n","The suspect is identified as a 17-year-old boy, who was fatally shot .\n"]}],"source":["   test_text = \"Recently, the topic of Artificial Intelligence Generated Content (AIGC) has witnessed unprecedented advancements 1NExT++ Research Center, National University of Singapore, Singapore. Correspondence to: Hao Fei <haofei37@nus.edu.sg>. Proceedings of the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author(s). with certain technologies, such as ChatGPT for text generation (OpenAI, 2022a) and diffusion models for visual generation (Fan et al., 2022). Among these, the rise of Large Language Models (LLMs) has been particularly remarkable, e.g., Flan-T5 (Chung et al., 2022), Vicuna (Chiang et al., 2023), LLaMA (Touvron et al., 2023) and Alpaca (Taori et al., 2023), showcasing their formidable human-level language reasoning and decision-making capabilities, shining a light on the path of Artificial General Intelligence (AGI). Our world is inherently multimodal, and humans perceive the world with different sensory organs for varied modal information, such as language, images, videos, and sounds, which often complement and synergize with each other. With such intuition, the purely text-based LLMs have recently been endowed with other modal understanding and perception capabilities of image, video, audio, etc. A notable approach involves employing adapters that align pre-trained encoders in other modalities to textual LLMs.This endeavor has led to the rapid development of multimodal LLMs (MM-LLMs), such as BLIP-2 (Li et al., 2023c), Flamingo (Alayrac et al., 2022), MiniGPT-4 (Zhu et al., 2023), Video-LLaMA (Zhang et al., 2023c), LLaVA (Liu et al., 2023b), PandaGPT (Su et al., 2023), and SpeechGPT (Zhang et al., 2023b). Nevertheless, most of these efforts pay attention to the multimodal content understanding at the input side. Lately, fewer works have considered multimodal generation, such as Emu (Sun et al., 2023), DREAMLLM (Dong et al., 2023), GILL (Koh et al., 2023), SEED (Ge et al., 2023). Notably, these models are confined to generating interleaved texts and images. We emphasize that natural human cognition and communication indispensably require seamless transitions between any modalities of information. This makes the exploration of any-to-any MM-LLMs critical, i.e., the ability to accept inputs in any modality and deliver responses in any appropriate modality.\"\n","   print(summarize(test_text))"]},{"cell_type":"raw","metadata":{},"source":["!pip install PyPDF2 transformers torch"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:26:22.397703Z","iopub.status.busy":"2024-12-27T21:26:22.396994Z","iopub.status.idle":"2024-12-27T21:26:32.486829Z","shell.execute_reply":"2024-12-27T21:26:32.485993Z","shell.execute_reply.started":"2024-12-27T21:26:22.397668Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}],"source":["!pip install PyPDF2 transformers torch"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-12-09T15:01:06.615041Z","iopub.status.busy":"2024-12-09T15:01:06.614785Z"}},"source":["!pip install PyPDF2 transformers torch"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:26:36.754378Z","iopub.status.busy":"2024-12-27T21:26:36.753994Z","iopub.status.idle":"2024-12-27T21:26:38.523993Z","shell.execute_reply":"2024-12-27T21:26:38.523104Z","shell.execute_reply.started":"2024-12-27T21:26:36.754343Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n","  warnings.warn(\n"]},{"data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n","      (layers): ModuleList(\n","        (0-11): 12 x BartEncoderLayer(\n","          (self_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n","      (layers): ModuleList(\n","        (0-11): 12 x BartDecoderLayer(\n","          (self_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",")"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import torch\n","\n","\n","model_path = \"/kaggle/working/trained_model\"  # Path where your model is saved\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:26:46.790474Z","iopub.status.busy":"2024-12-27T21:26:46.789629Z","iopub.status.idle":"2024-12-27T21:26:46.925685Z","shell.execute_reply":"2024-12-27T21:26:46.925004Z","shell.execute_reply.started":"2024-12-27T21:26:46.790442Z"},"trusted":true},"outputs":[],"source":["import PyPDF2\n","\n","def extract_text_from_pdf(file_path):\n","    with open(file_path, 'rb') as file:\n","        reader = PyPDF2.PdfReader(file)\n","        text = \"\"\n","        for page in reader.pages:\n","            text += page.extract_text()\n","    return text.split('\\n\\n')  "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:27:03.153139Z","iopub.status.busy":"2024-12-27T21:27:03.152323Z","iopub.status.idle":"2024-12-27T21:27:03.161277Z","shell.execute_reply":"2024-12-27T21:27:03.160345Z","shell.execute_reply.started":"2024-12-27T21:27:03.153108Z"},"trusted":true},"outputs":[],"source":["def summarize_paragraphs(paragraphs):\n","    summaries = []\n","    for paragraph in paragraphs:\n","        if paragraph.strip(): \n","            inputs = tokenizer(paragraph, return_tensors=\"pt\", max_length=1024, truncation=True)\n","            input_ids = inputs[\"input_ids\"].to(device)\n","            summary_ids = model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","            summaries.append(summary)\n","    return summaries"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:27:07.837942Z","iopub.status.busy":"2024-12-27T21:27:07.837110Z","iopub.status.idle":"2024-12-27T21:27:09.966882Z","shell.execute_reply":"2024-12-27T21:27:09.965984Z","shell.execute_reply.started":"2024-12-27T21:27:07.837910Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1493: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Paragraph 1 Summary: \n","\n"]}],"source":["def summarize_pdf(file_path):\n","    paragraphs = extract_text_from_pdf(file_path)\n","    summaries = summarize_paragraphs(paragraphs)\n","    for i, summary in enumerate(summaries):\n","        print(f\"Paragraph {i+1} Summary: {summary}\\n\")\n","\n","\n","pdf_file_path = \"/kaggle/input/pdf-test/AMovieRecommenderSystemMOVREC.pdf\"  # Replace with your PDF file path\n","summarize_pdf(pdf_file_path)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:27:20.528951Z","iopub.status.busy":"2024-12-27T21:27:20.528245Z","iopub.status.idle":"2024-12-27T21:27:20.534400Z","shell.execute_reply":"2024-12-27T21:27:20.533522Z","shell.execute_reply.started":"2024-12-27T21:27:20.528916Z"},"trusted":true},"outputs":[],"source":["import PyPDF2\n","\n","def extract_text_from_pdf(file_path):\n","    with open(file_path, 'rb') as file:\n","        reader = PyPDF2.PdfReader(file)\n","        text = \"\"\n","        for page in reader.pages:\n","            text += page.extract_text()\n","    return text.split('\\n\\n')  "]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:27:33.183468Z","iopub.status.busy":"2024-12-27T21:27:33.182746Z","iopub.status.idle":"2024-12-27T21:27:44.767512Z","shell.execute_reply":"2024-12-27T21:27:44.766692Z","shell.execute_reply.started":"2024-12-27T21:27:33.183437Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","\n","model_name = \"facebook/bart-large-cnn\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","def summarize_paragraphs(paragraphs):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    \n","    summaries = []\n","    for paragraph in paragraphs:\n","        if paragraph.strip(): \n","            inputs = tokenizer(\"summarize: \" + paragraph, return_tensors=\"pt\", max_length=1024, truncation=True)\n","            input_ids = inputs[\"input_ids\"].to(device)\n","            summary_ids = model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","            summaries.append(summary)\n","    return summaries"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T21:27:49.736340Z","iopub.status.busy":"2024-12-27T21:27:49.735223Z","iopub.status.idle":"2024-12-27T21:27:51.547366Z","shell.execute_reply":"2024-12-27T21:27:51.546680Z","shell.execute_reply.started":"2024-12-27T21:27:49.736289Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Paragraph 1 Summary: A Movie Recommender System: MOVREC is published in the International Journal of Comput er Applic ations. It is based on collaborative filtering that makes use of the information provided by users. It then recommends the movies that is best suited to the user at that time. The recommended movie list is sorted according to the ratings given to these movies by previous users.\n","\n"]}],"source":["def summarize_pdf(file_path):\n","    paragraphs = extract_text_from_pdf(file_path)\n","    summaries = summarize_paragraphs(paragraphs)\n","    for i, summary in enumerate(summaries):\n","        print(f\"Paragraph {i+1} Summary: {summary}\\n\")\n","\n","\n","pdf_file_path = \"/kaggle/input/pdf-test/AMovieRecommenderSystemMOVREC.pdf\"\n","summarize_pdf(pdf_file_path)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6265728,"sourceId":10149709,"sourceType":"datasetVersion"}],"dockerImageVersionId":30805,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
